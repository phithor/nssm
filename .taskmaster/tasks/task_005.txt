# Task ID: 5
# Title: Aggregate Sentiment & Detect Buzz Anomalies
# Status: pending
# Dependencies: 4
# Priority: medium
# Description: Compute rolling sentiment per ticker and detect unusual spike in volume or polarity.
# Details:
• analytics/aggregator.py: query last N hours posts, groupby ticker 5-min window using pandas.
• Store results into sentiment_agg.
• Anomaly: z-score over 24h mean of post_cnt; threshold >2.
• anomalies table(id,ticker,window_start,zscore,direction)
• Scheduled hourly.

# Test Strategy:
Unit test z-score logic with synthetic data. Integration test: load fixture counts → expect anomaly flagged when spike 3x.

# Subtasks:
## 1. Implement Recent Posts Query [pending]
### Dependencies: None
### Description: Use SQLAlchemy to retrieve posts and their sentiment scores from the last N hours per ticker.
### Details:
Create function get_recent_posts(session, hours_back) in analytics/aggregator.py. Ensure proper indexes on posts.timestamp and posts.ticker for performance.

## 2. Compute 5-Minute Window Aggregates [pending]
### Dependencies: 5.1
### Description: Group the queried data by ticker and 5-minute window using pandas to calculate avg_score and post_cnt.
### Details:
Use pandas.Grouper(freq='5min') on a DataFrame built from step 1 results. Output DataFrame columns: ticker, interval_start, interval_end, avg_score, post_cnt.

## 3. Persist Aggregates to sentiment_agg [pending]
### Dependencies: 5.2
### Description: Insert or upsert the computed aggregates into the sentiment_agg table.
### Details:
Leverage SQLAlchemy bulk operations with ON CONFLICT DO UPDATE for upsert logic. Wrap in transaction and commit.

## 4. Detect Anomalies and Record to anomalies Table [pending]
### Dependencies: 5.3
### Description: Calculate z-score over 24-hour rolling mean of post_cnt per ticker and store spikes crossing threshold ±2.
### Details:
For each ticker, maintain 24h history using sentiment_agg. Compute z = (current_cnt-mean)/std. Insert into anomalies table with direction = 'positive' or 'negative'.

## 5. Schedule Hourly Aggregation Job & Optimize DB [pending]
### Dependencies: 5.3, 5.4
### Description: Configure scheduler to run aggregator hourly and add necessary DB optimizations.
### Details:
Use schedule or APScheduler in a CLI entry point. Create indexes on sentiment_agg(ticker, interval_start) and anomalies(ticker, window_start). Ensure job logs metrics.

## 6. Create Unit Tests for Aggregation & Anomaly Logic [pending]
### Dependencies: 5.4
### Description: Write pytest cases with synthetic data to validate aggregation correctness and anomaly detection thresholds.
### Details:
Generate synthetic DataFrame, run through aggregation/anomaly functions, and assert expected rows in sentiment_agg and anomalies. Use pytest fixtures and in-memory SQLite.

